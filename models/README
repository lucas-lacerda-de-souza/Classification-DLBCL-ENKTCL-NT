üìò Model Categories
1. Multimodal Deep Learning
These scripts perform multimodal fusion between CNN features and clinical/morphometric embeddings for patch-level and patient-level classification.

Supported CNN Architectures
AlexNet
ResNet50
ConvNeXt-XLarge

Scripts
                Script    	                   ‚îÇ         Level	       ‚îÇ                                 Description
multimodal_alexnet_patch_level.py	           ‚îÇ         Patch	       ‚îÇ              AlexNet-based multimodal for patch-level prediction.
multimodal_alexnet_patient_level.py	           ‚îÇ        Patient	       ‚îÇ              Patient-level AlexNet classifier (mean pooled).
multimodal_resnet50_patch_level.py	           ‚îÇ         Patch	       ‚îÇ          ResNet50 classifier integrating image patches + clinical data.
multimodal_resnet50_patient_level.py	       ‚îÇ        Patient	       ‚îÇ        Aggregated patient-level inference based on ResNet50 outputs.
multimodal_convnextxlarge_patch_level.py	   ‚îÇ         Patch	       ‚îÇ               ConvNeXt-XLarge multimodal fusion at patch level.
multimodal_convnextxlarge_patient_level.py	   ‚îÇ        Patient	       ‚îÇ        ConvNeXt-XLarge patient-level prediction using aggregated patch probabilities.

All multimodal models include:
Late fusion (CNN + MLP embeddings)
Weighted cross-entropy for class imbalance
ROC, AUC, PR curve, confusion matrix generation
Patch-level and patient-level evaluation
Multi-GPU support (torch.nn.DataParallel)

2. Image Segmentation
Script	Description
segmentation_unet++.py	U-Net++ with attention for tissue segmentation and ROI extraction prior to patch generation.

3. Classical Machine Learning
Script	Description
xgboost_classification_cpc_mpa.R	XGBoost classifier trained on clinicopathologic and morphometric parameters.
xgboost_classification_gradcam.R	XGBoost model trained on Grad-CAM-derived features for interpretability and cross-validation.

Both scripts support:
Training/validation/test split
Feature importance plots
Confusion matrix and ROC/PR evaluation
CSV export of results to /results/

‚öôÔ∏è Usage Example
Train a multimodal ResNet50 model (patch-level)
python multimodal_resnet50_patch_level.py \
    --data_dir ./data/train \
    --val_dir ./data/val \
    --epochs 100 \
    --batch_size 64 \
    --output_dir ./results/resnet50_patch/

Run XGBoost Grad-CAM analysis
python xgboost_classification_gradcam.py \
  --input ./supplementary_data/supplementary_table_4.xlsx \
  --output ./results/xgboost_gradcam/

üìÅ Output Structure
results/

‚îú‚îÄ‚îÄ resnet18_patch/

‚îÇ   ‚îú‚îÄ‚îÄ model.pth

‚îÇ   ‚îú‚îÄ‚îÄ metrics.csv

‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png

‚îÇ   ‚îú‚îÄ‚îÄ roc_curve.png

‚îÇ   ‚îî‚îÄ‚îÄ pr_curve.png

‚îú‚îÄ‚îÄ unetpp_segmentation/

‚îÇ   ‚îú‚îÄ‚îÄ masks/

‚îÇ   ‚îî‚îÄ‚îÄ training_curves.png

‚îî‚îÄ‚îÄ xgboost_gradcam/

    ‚îú‚îÄ‚îÄ feature_importance.png

    ‚îú‚îÄ‚îÄ shap_summary.png

    ‚îî‚îÄ‚îÄ performance_metrics.csv

‚öôÔ∏è Model Configuration and Training Details
1. Traditional Machine Learning (XGBoost)
Objective: Binary logistic regression
Boosting rounds: 100
Learning rate: 0.1
Maximum tree depth: 6
Train/test split: 70% / 30%
Evaluation metrics: Accuracy, AUC, F1-score, Precision, Recall
Feature interpretability: SHAP (p > 0.1)

2. Nuclear Segmentation (U-Net++)
Architecture: U-Net++ with attention gates
Framework: PyTorch
Input size: 256 √ó 256 pixels
Training: NuInsSeg (665 images, ~30,000 annotated nuclei)
Data split: 80% training / 10% validation / 10% test
Optimizer: Adam (learning rate = 1 √ó 10‚Åª‚Å¥)
Loss function: Binary Cross-Entropy with Logits
Batch size: 4
Epochs: 50
Precision mode: Mixed (CUDA acceleration)

3. Patch Generation and Pre-processing
Patch size: 299 √ó 299 pixels
Patch overlap: 20%
Color normalization: Macenko method
Data augmentation: Rotations (90¬∞, 180¬∞, 270¬∞) and Gaussian blur
Data split:
From 136 patients (68 DLBCL ‚Äì Class 1, 68 ENKTCL-NT ‚Äì Class 2):
Internal patient-level split:
Training (80%) ‚Üí 85 cases
43 Class 1 ‚Üí 82,679 patches
42 Class 2 ‚Üí 79,978 patches
Validation (10%) ‚Üí 12 cases
6 Class 1 ‚Üí 8,896 patches
6 Class 2 ‚Üí 7,621 patches
Test (10%) ‚Üí 12 cases
6 Class 1 ‚Üí 8,093 patches
6 Class 2 ‚Üí 8,074 patches
External Validation
External 1 (13 cases)
7 Class 1 ‚Üí 7,146 patches
6 Class 2 ‚Üí 7,853 patches
External 2 (14 cases)
6 Class 1 ‚Üí 7,004 patches
8 Class 2 ‚Üí 7,413 patches

4. Multimodal Deep Learning (CNN + MLP Fusion)
Backbones: AlexNet, ResNet50 and ConvNeXt-XLarge (ImageNet pretrained)
Fusion strategy: Late fusion (concatenation of CNN and MLP embeddings)
MLP branch: Fully connected layers with ReLU activation and dropout regularization
Optimizer: AdamW (learning rate = 1 √ó 10‚Åª‚Å¥, weight decay = 1 √ó 10‚Åª‚Å¥)
Loss function: Weighted Cross-Entropy
Batch size: 64
Computation: Mixed precision (CUDA)
Aggregation (patient-level): Mean of patch-level probabilities

üß¨ Reproducibility Notes
Python: 3.12.11
PyTorch: 2.8.0 + CUDA 12.8
GPU: 3 √ó NVIDIA RTX 3090 (24 GB each)
OS: Ubuntu 20.04 LTS
RAM: 125 GB
Random seeds are fixed (torch, numpy, random) for deterministic behavior.

























